---
title: "Client Satisfaction Report"
subtitle: "Part 3 of 3: Analysis of Customer Sat Comments"
date: "August 2019 (Surveys 1-4)"
output: "html_document"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, out.width='90%')
pagebreak <- function() {
  if(knitr::is_latex_output())
    return("\\newpage")
  else
    return('<div style="page-break-before: always;" />')
}
```

### Overview

This report analyzes the occurrences of positive and negative vocabulary words in the comments field of the TSG customer satisfaction surveys. The statistics are for four surveys, taken as follows:

* Fall 2018
* Winter 2019
* Spring 2019
* Summer 2019

Note that each survey was distributed to a unique 25% of the organization, and therefore does not follow the principle of random selection. The surveys provide some sense of the organization's opinions.

Words used by responders can provide some useful insight into how responders are thinking and what troubles (or delights) them most. Totaling the number of occurrences of positives and negatives and looking at various ratos can provide some sense of how happy responders are (and with what). 

Positive / negative vocabularly words were selected by reading through the comments manually, examining the context, and selecting those that would, in as many cases as possible, be unambiguous. The code reads each comment, and tabulates the number of occurrences of each word on the list - cumulatively, and by individual survey.

This report includes graphs to help visualize the relative number of occurrences per comment, and to compare the various proportions / ratios of positives and negatives. The graphs and charts provide some insight into trends, but with only three surveys to work with, these trends have to be looked on as tentative.

### Summary

Through the four surveys taken to date, the following trends are emerging: [REVISE]

* The number of comments is increasing with each survey
* The number of positive vocabularly occurrences is increasing with each survey
* The number of positive vocabularly occurrences is increasing faster than the increase in comments
* The number of negative vocabularly occurrences is decreasing with each survey, but slowly
* The number of negative vocuabulary occurrences is noticeably less than the number of positive occurrences

In short, the positives are going up and the negatives are going down. This could be a fact, but also could be coincidental.

### Other Notes and Recommendations

* Please collect the "best practices" and new software ideas from all employees and share them with others to improve everyone's productivity.

`r pagebreak()`

```{r File open and setup, include=FALSE}
#
# Library setups
#

# Import libraries
library(tidyverse)
library(tidyr)
library(plyr)
library(dplyr)
library(caret)
library(ggplot2)
library(ggthemes)
library(extrafont)
library(scales)
library(reshape2)
library(stringi)
library(expss)
library(grid)
library(gridExtra)
library(lattice)
library(janitor)
library(rmarkdown)
library(kableExtra)

#--------------------------------------------------------------------
#
# File open, cleanup, and set up for the analysis
#
#--------------------------------------------------------------------

#
# Download and open survey file
#


# Import and Open the data file / Establish the data set
data_filename <- "0_Input_CustSatData.csv"
dat <- read.csv(data_filename, stringsAsFactors = FALSE)

vocab_filename <- "0_Input_Vocabulary.csv"
comms          <- read.csv(vocab_filename, stringsAsFactors = FALSE)
pos_vocab      <- comms %>% filter(Tone == "P")
neg_vocab      <- comms %>% filter(Tone == "N")

#
# Convert time stamps to survey names
#

# Trap for 2018 survey
for(i in 1:length(dat$Timestamp)) {
  x <- str_detect(dat$Timestamp[i], "2018")
  if(x == TRUE) {
    dat$Timestamp[i] <- "01 - Fall 2018"
  }
}

# Trap for 2019 surveys
for(i in 1:length(dat$Timestamp)) {
  if(dat$Timestamp[i] > "1/1/2019" & dat$Timestamp[i] < "4/1/2019") {
    dat$Timestamp[i] <- "02 - Winter 2019"
  }
  if(dat$Timestamp[i] > "4/1/2019" & dat$Timestamp[i] < "6/30/2019") {
    dat$Timestamp[i] <- "03 - Spring 2019"
  }

  if(dat$Timestamp[i] > "7/1/2019" & dat$Timestamp[i] < "9/30/2019") {
    dat$Timestamp[i] <- "04 - Summer 2019"
  }
}

#
# Clean data file to set vector names
#

dat <- rename(dat, replace = c("Timestamp" = "Surveyed",
                               "Tell.us.about.your.experience.working.with.us..TSG.makes.a.positive.contribution.to.my.work." = "PosContrib",
                               "Tell.us.about.your.experience.working.with.us..TSG.responds.to.my.requests.in.a.timely.manner." = "TimelyResp",
                               "Tell.us.about.your.experience.working.with.us..TSG.takes.accountability.for.my.requests." = "Accountability",
                               "Tell.us.about.your.experience.working.with.us..TSG.staff.are.knowledgable.." = "Knowledgeable",
                               "Please.rate.your.satisfaction.with.our.services...Account.manager.support." = "AcctMgrs",
                               "Please.rate.your.satisfaction.with.our.services...Audio.and.Video.Production.Services." = "BMPS",
                               "Please.rate.your.satisfaction.with.our.services...Business.applications.support..M.files..Salesforce..Enterprise..etc..." = "BusApps",
                               "Please.rate.your.satisfaction.with.our.services...Event.services." = "EventSvcs",
                               "Please.rate.your.satisfaction.with.our.services...Project.support." = "ProjSupp",
                               "Please.rate.your.satisfaction.with.our.services...Service.Desk." = "ServDesk",
                               "Please.rate.your.satisfaction.with.our.services...Studio.services." = "StudioSvcs",
                               "Please.rate.your.satisfaction.with.our.services...Vendor.management.services." = "VenMgmt",
                               "Is.there.anything.else.you.would.like.to.share." = "Comments"))

# Remove rows below the actual data
cleandat <- subset(dat, dat[ , 1] != "")

# Select the desired columns
wkgdat <- cleandat %>% select(Surveyed,	Comments, PosContrib,	TimelyResp,	
                              Accountability, Knowledgeable,	AcctMgrs,	
                              BMPS,	BusApps,	EventSvcs, ProjSupp,	ServDesk,	
                              StudioSvcs,	VenMgmt)

# Rename ratings so they will sort
wkgdat[wkgdat == "Always"]            <- "1-Always"
wkgdat[wkgdat == "Mostly"]            <- "2-Mostly"
wkgdat[wkgdat == "Sometimes"]         <- "3-Sometimes"
wkgdat[wkgdat == "Rarely"]            <- "4-Rarely"
wkgdat[wkgdat == "Never"]             <- "5-Never"

# Rename group ratings to be consistent
wkgdat[wkgdat == "Very Satisfied"]    <- "1-Very Satisfied"
wkgdat[wkgdat == "Satisfied"]         <- "2-Satisfied"
wkgdat[wkgdat == "Neutral"]           <- "3-Neutral"
wkgdat[wkgdat == "Dissatisfied"]      <- "4-Dissatisfied"
wkgdat[wkgdat == "Very Dissatisfied"] <- "5-Very Dissatisfied"

# Change survey names to shorter form
for(i in 1:length(unique(wkgdat$Surveyed))) {
  sssq <- str_sub(unique(wkgdat$Surveyed)[i],  6,  6)
  sssy <- str_sub(unique(wkgdat$Surveyed)[i], -2, -1)
  survey_name <- paste(as.character(0), as.character(i), "-", sssq, as.character(sssy))
  survey_name <- str_replace_all(survey_name, " ", "")
  wkgdat[wkgdat == unique(wkgdat$Surveyed)[i]] <- survey_name
}

# Replace missing values (zeros) with NR and shorten "do not use"
wkgdat[wkgdat == 0]                   <- "NR"
wkgdat[wkgdat == ""]                  <- "NR"
wkgdat[wkgdat == "N/A do not use"]    <- "NA/DNU"

# Verify the number of unique values of the various factors
# sapply(wkgdat, function(x)length(unique(x)))

# Calc the number of comments
num_comments <- length(unique(wkgdat$Comments))
```

### Cumulative View

This section looks at the cumulative picture and summarizes the statistics and vocabularly occurrences (positive and negative) across all surveys to date. 

The Top 10 Postive and Negative words are shown below. See the Appendix for a complete list of word occurrences and counts.

```{r Cumulative Statistics, echo=FALSE, comment=NA}

#--------------------------------------------------------------------
#
# Vocabulary analysis - Cumulative
#
#--------------------------------------------------------------------

#
# Positive vocabulary elements
#

# Build dataframe for positives
pos_df   <- data.frame(Word  = pos_vocab$Term,
                       Count = 1:nrow(pos_vocab),
                       Type  = "P")

# Loop to identify positive words in the comments field
pct <- 0
for(i in 1:nrow(pos_vocab)) {
  x <- str_detect(wkgdat$Comments, pos_vocab$Term[i])
  pos_df[i, 2] <- length(x[x == TRUE])
  pct <- pct + length(x[x == TRUE])
}

# Remove words with zero counts
pos_df  <- pos_df %>% filter(Count != 0)

# Sort from high to low
pos_df <- arrange(pos_df, desc(Count), Word)

cat("Top 10 Positive Words")
pos_df[1:10, ]

# 
# Negative vocabulay elements
#

# Build dataframe for negatives
neg_df   <- data.frame(Word  = neg_vocab$Term,
                       Count = 1:nrow(neg_vocab),
                       Type  = "N")


# Loop to identify negative words in the comments field
nct <- 0
for(i in 1:nrow(neg_vocab)) {
  x <- str_detect(wkgdat$Comments, neg_vocab$Term[i])
  neg_df[i, 2] <- length(x[x == TRUE])
  nct <- nct + length(x[x == TRUE])
}

# Remove words with zero counts
neg_df   <- neg_df %>% filter(Count != 0)

# Sort from high to low
neg_df <- arrange(neg_df, desc(Count), Word)

cat("Top 10 Negative Words")
neg_df[1:10, ]

# Create datafrane and append negatives
cum_count_df <- pos_df
cum_count_df <- rbind(cum_count_df, neg_df)

# Determine overall positive and negative indexes (pos / neg words / comments
pos_index <- sum(pos_df$Count) / num_comments
neg_index <- sum(neg_df$Count) / num_comments

# Create a filename and write out the results
# filename <- paste("0_Output_cum_survey_data",".csv")
# filename <- stri_replace_all_fixed(filename, " ", "")
# write.csv(cum_count_df, file = filename)

cat("Summary Statistics for All Surveys", "\n",
    "Number of survey responses      :", nrow(wkgdat), "\n",
    "Number of survey comments       :", num_comments, "\n",
    "Comments to responses ratio     :", num_comments / nrow(wkgdat), "\n",
    "Number of positive words        :", pct, "\n",
    "Positive words to comments ratio:", pos_index, "\n",
    "Number of negative words        :", nct, "\n",
    "Negative words to comments ratio:", neg_index, "\n")
cat("\n")

```

A second appendix includes a word cloud version of the entire comments set.

`r pagebreak()`
### Individual Survey View

This section looks at the positive and negative vocabularly tabulations by individual surveys. Explanations of the various statistics are given below.

```{r Analysis by Survey, echo=FALSE, comment=NA}
#--------------------------------------------------------------------
#
# Vocabulary analysis - by Survey
# 
#--------------------------------------------------------------------
# Set the number of surveys 
survey_num <- length(unique(wkgdat$Surveyed))

# Dataframe to collect all the data and calculations
survey_inf <- data.frame(Survey        = survey_num,
                         num_resps     = survey_num,
                         num_comments  = survey_num,
                         c_to_r_ratio  = survey_num,
                         num_pos_words = survey_num,
                         pw_to_c_ratio = survey_num,
                         num_neg_words = survey_num,
                         nw_to_c_ratio = survey_num)


# Loop to examine each survey and assign values to a dataframe
for(i in 1:survey_num) {
  
  #
  # Positive vocabulary elements
  #
  
  # Build dataframe
  sur_pos_df <- data.frame(Survey = unique(wkgdat$Surveyed)[i],
                           Word   = pos_vocab$Term,
                           Count  = 0,
                           Type   = "P")
  
  # Set the specific survey data
  survey_dat  <- wkgdat %>% filter(Surveyed == unique(wkgdat$Surveyed)[i])
  survey_comments <- length(unique(survey_dat$Comments))
  
  # Loop to count the occurrences of positive words
  pct <- 0
  for(j in 1:nrow(pos_vocab)) {
     x <- str_detect(survey_dat$Comments, pos_vocab$Term[j])
     sur_pos_df[j, 3] <- length(x[x == TRUE])
     pct <- pct + length(x[x == TRUE])
  }

  # Remove words with zero counts
  sur_pos_df  <- sur_pos_df %>% filter(Count != 0)
  
  # Sort from high to low
  sur_pos_df <- arrange(sur_pos_df, desc(Count), Word)
  sur_pos_df
  
  #
  # Negative vocabulary elements
  #

  # Build dataframe
  sur_neg_df <- data.frame(Survey = unique(wkgdat$Surveyed)[i],
                           Word   = neg_vocab$Term,
                           Count  = 0,
                           Type   = "N")
  
  # Loop to count the occurrences of negative words
  nct <- 0
  for(j in 1:nrow(neg_vocab)) {
    x <- str_detect(survey_dat$Comments, neg_vocab$Term[j])
    sur_neg_df[j, 3] <- length(x[x == TRUE])
    nct <- nct + length(x[x == TRUE])
  }

  # Remove words with zero counts
  sur_neg_df  <- sur_neg_df %>% filter(Count != 0)
  
  # Sort from high to low
  sur_neg_df <- arrange(sur_neg_df, desc(Count), Word)
  sur_neg_df
  
  # Create combined dataframe
  sur_cum_df <- sur_pos_df
  
  # Append to the cumulative dataframe
  sur_cum_df <- rbind(sur_cum_df, sur_neg_df)
  
  # Create the unique filename by survey and write out the results
  # filename <- paste("0_Output_", sur_cum_df[i,1],".csv")
  # filename <- stri_replace_all_fixed(filename, " ", "")
  # write.csv(sur_cum_df, file = filename)
  
  #
  # Print results of individual surveys
  #
  
  kable(sur_cum_df) %>%
    kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
  
  # Populate summary dataframe
  survey_inf[i, 1] <- unique(wkgdat$Surveyed)[i]
  survey_inf[i, 2] <- nrow(survey_dat)
  survey_inf[i, 3] <- survey_comments
  survey_inf[i, 4] <- round(survey_comments / nrow(survey_dat), digits = 2)
  survey_inf[i, 5] <- pct
  survey_inf[i, 6] <- round(pct / survey_comments, digits = 2)
  survey_inf[i, 7] <- nct
  survey_inf[i, 8] <- round(nct / survey_comments, digits = 2)
    
  # Display results and statistics
  cat("Results for", survey_inf[i, 1], "\n")  
  cat("Number of responses             :", survey_inf[i, 2], "\n")  
  cat("Number of comments              :", survey_inf[i, 3], "\n")  
  cat("Comments to responses ratio     :", survey_inf[i, 4], "\n")  
  cat("Number of positive words        :", survey_inf[i, 5], "\n")  
  cat("Positive words to comments ratio:", survey_inf[i, 6], "\n")  
  cat("Number of negative words        :", survey_inf[i, 7], "\n")  
  cat("Negative words to comments ratio:", survey_inf[i, 8], "\n")  
  cat("\n")  
}
```

**Overall Summary of Individual Survey Statistics**

Translation of field names:

* num_resp = number of responses
* num_comments = the number of comments in the survey
* c_to_r_ratio = the number of comments divided by the number of responses
* num_pos_words = the number of positive words found in the survey
* pw_to_c_ratio = the number of positive words divided by the number of comments
* num_neg_words = the number of negative words found in the survey
* nw_to_c_ratio = the number of negative words divided by the number of comments

```{r Summary Table, echo=FALSE}
kable(survey_inf) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

Graphical representations of the summary statistics by Survey are shown below.

```{r Graphics, echo=FALSE, fig.width=10,fig.height=5}
#--------------------------------------------------------------------
#
# Build graphics from summary dataframe
#
#--------------------------------------------------------------------

# Number of coments and responses by survey
num_c_and_r <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=num_resps, color = "Responses"), group=1, size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=num_comments, color = "Comments"), group=1, size=2) +
  scale_colour_manual("", 
                      breaks = c("Responses", "Comments"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Count of Comments and Responses", subtitle = "Numbers of each by Survey") + ylab("Number") +
  theme(legend.position = c(0.18,0.85))

# Ratio of comments to responses
ratio_c_to_r <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=c_to_r_ratio, color = "Ratios", group=1), size=2) +
  scale_colour_manual("", breaks = c("Ratios"), values = c("#000099")) +
  labs(title = "Ratio of Comments to Responses", subtitle = "Ratio By Survey") + ylab("Proportion of Comments") +
  theme(legend.position = c(0.15,0.88))

# Arrange the two plots for pasting into deck
grid.arrange(num_c_and_r, ratio_c_to_r, ncol = 2)

# Positive words vs. comments
pw_vs_c <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=num_pos_words, color = "Positive Words", group=1), size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=num_comments, color = "Comments", group=1), size=2) +
  scale_y_continuous(limits=c(0, 60)) +
  scale_colour_manual("", 
                      breaks = c("Positive Words", "Comments"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Positive Words vs. Comments", subtitle = "Number of each by Survey") + ylab("Number of Each") +
  theme(legend.position = c(0.2,0.85))

# Negative words vs. comments
nw_vs_c <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=num_neg_words, color = "Negative Words", group=1), size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=num_comments, color = "Comments", group=1), size=2) +
  scale_y_continuous(limits=c(0, 60)) +
  scale_colour_manual("", 
                      breaks = c("Negative Words", "Comments"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Negative Words vs. Comments", subtitle = "Number of each by Survey") + ylab("Number of Each") +
  theme(legend.position = c(0.22,0.85))

# Arrange the two plots for pasting into deck
grid.arrange(pw_vs_c, nw_vs_c, ncol = 2)

# Positive and negative words to comments ratios
p_vs_n <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=pw_to_c_ratio, color = "Positive", group=1), size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=nw_to_c_ratio, color = "Negative", group=1), size=2) +
  scale_colour_manual("", 
                      breaks = c("Positive Words", "Negative Words"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Ratios of Positive & Negative Words to Comments", subtitle = "Ratio Comparisons by Survey") +
  ylab("# Words / # Comments") +
  theme(legend.position = c(0.22,0.85))

# Arrange the two plots for pasting into deck
grid.arrange(p_vs_n, ncol = 2)

```

`r pagebreak()`

### Appendix - Summary of Positive Vocabularly Words

**Positive Vocabulary word counts / occurrences**

```{r Display Positive Results, echo=FALSE}
kable(pos_df) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

`r pagebreak()`

### Appendix - Summary of Negative Vocabularly Words

**Negative Vocabulary word counts / occurrences**

```{r Display Negative Results, echo=FALSE}
kable(neg_df) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

`r pagebreak()`

### Appendix - A Word Cloud Version of All Comments

This word cloud was created using one of the available tools on the internet (in this case, https://wordart.com) and then feeding the entire comments set into the application. Common words were automatically removed (in, the, a, at, etc.).

![Word Cloud of All Survey Comments](3-CustSatReport-Comments.png)

```{r echo=FALSE}
#--------------------------------------------------------------------
#
# End
#
#--------------------------------------------------------------------
```

