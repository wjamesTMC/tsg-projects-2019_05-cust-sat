---
title: "Client Satisfaction Report"
subtitle: "Part 3 of 3: Analysis of Customer Sat Comments"
date: "July 2019"
output: "html_document"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, out.width='90%')
pagebreak <- function() {
  if(knitr::is_latex_output())
    return("\\newpage")
  else
    return('<div style="page-break-before: always;" />')
}
```

### Overview

This report analyzes the occurrences of positive and negative vocabulary words in the comments field of the TSG customer satisfaction surveys. 

While an examination of the words used by responders is not completely precise, it can provide some useful insight into how responders are thinking and what troubles (or delights) them most. For example, the word "help" could be construed as positive or negative (e.g., "was a big help" vs. "no help at all") but a manual review of all the comments suggests that it is always used in a positive context, and therefore was made a "positive" word. Totaling the number of occurrences of positives and negatives and looking at various ratos can provide some sense of how happy responders are (and with what). 

In contrast, it is also possible to generate (automatically) a word cloud of *all* the words used in the comments (excluding common words such as "a", the", "in" and so forth). This provides a high level (and different) view which provides some additional insightslike the name of a help desk person who has been particularly helpful and therefore called out (e.g., "Sean"). However, word clouds do not differentiate between positive and negative, and some words (like "Service Desk") are left in that are less useful in trying to establish an overall tone.

Working with the comments confirmed the value of constructing a specific vocabularly to run against the comment fields.

This report includes graphs to help visualize the relative number of occurrences per comment, and to compare the various proportions / ratios of positives and negatives. The graphs and charts provide some insight into trends, but with only three surveys to work with, these trends have to be looked on as tentative.

### Approach

Positive / negative vocabularly words were selected by reading through the comments manually, examining the context, and selecting those that would, in as many cases as possible, be unambiguous. The code reads each comment, and tabulates the number of occurrences of each word on the list - cumulatively, and by individual survey.

Graphs then chart the total positive and negative occurrences, and compares these totals in various ways to establish a sense of tone, and then compares positive and negative totals with each other to see if both are going up, down, or trending differently.

As a side note, the word "Enterprise" (referring to the business application) appears to be rather negatively perceived by survey responders, and was given its own entry in the negative vocabularly list.

### Findings

With only three surveys taken to date, it is difficult to be certain about trends, but it *appears* that the following conclusions could be reached:

* The number of comments is increasing with each survey
* The number of positive vocabularly occurrences is increasing with each survey
* The number of positive vocabularly occurrences is increasing faster than the increase in comments
* The number of negative vocabularly occurrences is decreasing with each survey, but slowly
* The number of negative vocuabulary occurrences is noticeably less than the number of positive occurrences

In short, the positives are going up and the negatives are going down. This could be a fact, but also could be coincidental.

`r pagebreak()`

```{r File open and setup, echo=FALSE}
#
# Library setups
#

# Import libraries
library(tidyverse)
library(tidyr)
library(plyr)
library(dplyr)
library(caret)
library(ggplot2)
library(ggthemes)
library(extrafont)
library(scales)
library(reshape2)
library(stringi)
library(expss)
library(grid)
library(gridExtra)
library(lattice)
library(janitor)
library(rmarkdown)
library(kableExtra)

#--------------------------------------------------------------------
#
# File open, cleanup, and set up for the analysis
#
#--------------------------------------------------------------------

#
# Download and open survey file
#

# Import and Open the data file / Establish the data sets
data_filename  <- "0_Input_CustSatData.csv"
dat            <- read.csv(data_filename, stringsAsFactors = FALSE)

vocab_filename <- "0_Input_Vocabulary.csv"
comms          <- read.csv(vocab_filename, stringsAsFactors = FALSE)
pos_vocab      <- comms %>% filter(Tone == "P")
neg_vocab      <- comms %>% filter(Tone == "N")

#
# Clean data file to set vector names
#

# Rename vectors from survey questions to variable names
dat <- rename(dat, replace = c("Tell.us.about.your.experience.working.with.us..TSG.makes.a.positive.contribution.to.my.work." = "PosContrib",
                               "Tell.us.about.your.experience.working.with.us..TSG.responds.to.my.requests.in.a.timely.manner." = "TimelyResp",
                               "Tell.us.about.your.experience.working.with.us..TSG.takes.accountability.for.my.requests." = "Accountability",
                               "Tell.us.about.your.experience.working.with.us..TSG.staff.are.knowledgable.." = "Knowledgeable",
                               "Please.rate.your.satisfaction.with.our.services...Account.manager.support." = "AcctMgrs",
                               "Please.rate.your.satisfaction.with.our.services...Audio.and.Video.Production.Services." = "BMPS",
                               "Please.rate.your.satisfaction.with.our.services...Business.applications.support..M.files..Salesforce..Enterprise..etc..." = "BusApps",
                               "Please.rate.your.satisfaction.with.our.services...Event.services." = "EventSvcs",
                               "Please.rate.your.satisfaction.with.our.services...Project.support." = "ProjSupp",
                               "Please.rate.your.satisfaction.with.our.services...Service.Desk." = "ServDesk",
                               "Please.rate.your.satisfaction.with.our.services...Studio.services." = "StudioSvcs",
                               "Please.rate.your.satisfaction.with.our.services...Vendor.management.services." = "VenMgmt",
                               "Is.there.anything.else.you.would.like.to.share." = "Comments"))

# Remove rows below the actual data
cleandat <- subset(dat, dat[ , 1] != "")

# Select the desired columns
wkgdat <- cleandat %>% select(Surveyed,	Comments, PosContrib,	TimelyResp,	
                              Accountability, Knowledgeable,	AcctMgrs,	
                              BMPS,	BusApps,	EventSvcs, ProjSupp,	ServDesk,	
                              StudioSvcs,	VenMgmt)

# Rename ratings so they will sort
wkgdat[wkgdat == "Always"]            <- "1-Always"
wkgdat[wkgdat == "Mostly"]            <- "2-Mostly"
wkgdat[wkgdat == "Sometimes"]         <- "3-Sometimes"
wkgdat[wkgdat == "Rarely"]            <- "4-Rarely"
wkgdat[wkgdat == "Never"]             <- "5-Never"

# Change survey names to shorter form
for(i in 1:length(unique(wkgdat$Surveyed))) {
  sssq <- str_sub(unique(wkgdat$Surveyed)[i],  6,  6)
  sssy <- str_sub(unique(wkgdat$Surveyed)[i], -2, -1)
  survey_name <- paste(as.character(0), as.character(i), "-", sssq, as.character(sssy))
  survey_name <- str_replace_all(survey_name, " ", "")
  wkgdat[wkgdat == unique(wkgdat$Surveyed)[i]] <- survey_name
}

# Replace missing values (zeros) with NR and shorten "do not use"
wkgdat[wkgdat == 0]                   <- "NR"
wkgdat[wkgdat == ""]                  <- "NR"
wkgdat[wkgdat == "N/A do not use"]    <- "NA/DNU"

# Verify the number of unique values of the various factors
# sapply(wkgdat, function(x)length(unique(x)))

# Calc the number of comments
num_comments <- length(unique(wkgdat$Comments))
```

### Cumulative View

This section looks at the cumulative picture and summarizes the statistics and vocabularly occurrences (positive and negative) across all surveys to date. 

The Top 10 Postive and Negative words are shown below. See the Appendix for a complete list of word occurrences and counts.

```{r Cumulative Statistics, echo=FALSE, comment=NA}

#--------------------------------------------------------------------
#
# Vocabulary analysis - Cumulative
#
#--------------------------------------------------------------------

#
# Positive vocabulary elements
#

# Build dataframe for positives
pos_df   <- data.frame(Word  = pos_vocab$Term,
                       Count = 1:nrow(pos_vocab),
                       Type  = "P")

# Loop to identify positive words in the comments field
pct <- 0
for(i in 1:nrow(pos_vocab)) {
  x <- str_detect(wkgdat$Comments, pos_vocab$Term[i])
  pos_df[i, 2] <- length(x[x == TRUE])
  pct <- pct + length(x[x == TRUE])
}

# Remove words with zero counts
pos_df  <- pos_df %>% filter(Count != 0)

# Sort from high to low
pos_df <- arrange(pos_df, desc(Count), Word)

cat("Top 10 Positive Words")
pos_df[1:10, ]

# 
# Negative vocabulay elements
#

# Build dataframe for negatives
neg_df   <- data.frame(Word  = neg_vocab$Term,
                       Count = 1:nrow(neg_vocab),
                       Type  = "N")


# Loop to identify negative words in the comments field
nct <- 0
for(i in 1:nrow(neg_vocab)) {
  x <- str_detect(wkgdat$Comments, neg_vocab$Term[i])
  neg_df[i, 2] <- length(x[x == TRUE])
  nct <- nct + length(x[x == TRUE])
}

# Remove words with zero counts
neg_df   <- neg_df %>% filter(Count != 0)

# Sort from high to low
neg_df <- arrange(neg_df, desc(Count), Word)

cat("Top 10 Negative Words")
neg_df[1:10, ]

# Create datafrane and append negatives
cum_count_df <- pos_df
cum_count_df <- rbind(cum_count_df, neg_df)

# Determine overall positive and negative indexes (pos / neg words / comments
pos_index <- sum(pos_df$Count) / num_comments
neg_index <- sum(neg_df$Count) / num_comments

# Create a filename and write out the results
# filename <- paste("0_Output_cum_survey_data",".csv")
# filename <- stri_replace_all_fixed(filename, " ", "")
# write.csv(cum_count_df, file = filename)

cat("Summary Statistics for All Surveys", "\n",
    "Number of survey responses      :", nrow(wkgdat), "\n",
    "Number of survey comments       :", num_comments, "\n",
    "Comments to responses ratio     :", num_comments / nrow(wkgdat), "\n",
    "Number of positive words        :", pct, "\n",
    "Positive words to comments ratio:", pos_index, "\n",
    "Number of negative words        :", nct, "\n",
    "Negative words to comments ratio:", neg_index, "\n")
cat("\n")

```

A second appendix includes a word cloud version of the entire comments set.

`r pagebreak()`
### Individual Survey View

This section looks at the positive and negative vocabularly tabulations by individual surveys. Explanations of the various statistics are given below.

```{r Analysis by Survey, echo=FALSE, comment=NA}
#--------------------------------------------------------------------
#
# Vocabulary analysis - by Survey
# 
#--------------------------------------------------------------------
# Set the number of surveys 
survey_num <- length(unique(wkgdat$Surveyed))

# Dataframe to collect all the data and calculations
survey_inf <- data.frame(Survey        = survey_num,
                         num_resps     = survey_num,
                         num_comments  = survey_num,
                         c_to_r_ratio  = survey_num,
                         num_pos_words = survey_num,
                         pw_to_c_ratio = survey_num,
                         num_neg_words = survey_num,
                         nw_to_c_ratio = survey_num)


# Loop to examine each survey and assign values to a dataframe
for(i in 1:survey_num) {
  
  #
  # Positive vocabulary elements
  #
  
  # Build dataframe
  sur_pos_df <- data.frame(Survey = unique(wkgdat$Surveyed)[i],
                           Word   = pos_vocab$Term,
                           Count  = 0,
                           Type   = "P")
  
  # Set the specific survey data
  survey_dat  <- wkgdat %>% filter(Surveyed == unique(wkgdat$Surveyed)[i])
  survey_comments <- length(unique(survey_dat$Comments))
  
  # Loop to count the occurrences of positive words
  pct <- 0
  for(j in 1:nrow(pos_vocab)) {
     x <- str_detect(survey_dat$Comments, pos_vocab$Term[j])
     sur_pos_df[j, 3] <- length(x[x == TRUE])
     pct <- pct + length(x[x == TRUE])
  }

  # Remove words with zero counts
  sur_pos_df  <- sur_pos_df %>% filter(Count != 0)
  
  # Sort from high to low
  sur_pos_df <- arrange(sur_pos_df, desc(Count), Word)
  sur_pos_df
  
  #
  # Negative vocabulary elements
  #

  # Build dataframe
  sur_neg_df <- data.frame(Survey = unique(wkgdat$Surveyed)[i],
                           Word   = neg_vocab$Term,
                           Count  = 0,
                           Type   = "N")
  
  # Loop to count the occurrences of negative words
  nct <- 0
  for(j in 1:nrow(neg_vocab)) {
    x <- str_detect(survey_dat$Comments, neg_vocab$Term[j])
    sur_neg_df[j, 3] <- length(x[x == TRUE])
    nct <- nct + length(x[x == TRUE])
  }

  # Remove words with zero counts
  sur_neg_df  <- sur_neg_df %>% filter(Count != 0)
  
  # Sort from high to low
  sur_neg_df <- arrange(sur_neg_df, desc(Count), Word)
  sur_neg_df
  
  # Create combined dataframe
  sur_cum_df <- sur_pos_df
  
  # Append to the cumulative dataframe
  sur_cum_df <- rbind(sur_cum_df, sur_neg_df)
  
  # Create the unique filename by survey and write out the results
  # filename <- paste("0_Output_", sur_cum_df[i,1],".csv")
  # filename <- stri_replace_all_fixed(filename, " ", "")
  # write.csv(sur_cum_df, file = filename)
  
  #
  # Print results of individual surveys
  #
  
  kable(sur_cum_df) %>%
    kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
  
  # Populate summary dataframe
  survey_inf[i, 1] <- unique(wkgdat$Surveyed)[i]
  survey_inf[i, 2] <- nrow(survey_dat)
  survey_inf[i, 3] <- survey_comments
  survey_inf[i, 4] <- round(survey_comments / nrow(survey_dat), digits = 2)
  survey_inf[i, 5] <- pct
  survey_inf[i, 6] <- round(pct / survey_comments, digits = 2)
  survey_inf[i, 7] <- nct
  survey_inf[i, 8] <- round(nct / survey_comments, digits = 2)
    
  # Display results and statistics
  cat("Results for", survey_inf[i, 1], "\n")  
  cat("Number of responses             :", survey_inf[i, 2], "\n")  
  cat("Number of comments              :", survey_inf[i, 3], "\n")  
  cat("Comments to responses ratio     :", survey_inf[i, 4], "\n")  
  cat("Number of positive words        :", survey_inf[i, 5], "\n")  
  cat("Positive words to comments ratio:", survey_inf[i, 6], "\n")  
  cat("Number of negative words        :", survey_inf[i, 7], "\n")  
  cat("Negative words to comments ratio:", survey_inf[i, 8], "\n")  
  cat("\n")  
}
```

**Overall Summary of Individual Survey Statistics**

Translation of field names:

* num_resp = number of responses
* num_comments = the number of comments in the survey
* c_to_r_ratio = the number of comments divided by the number of responses
* num_pos_words = the number of positive words found in the survey
* pw_to_c_ratio = the number of positive words divided by the number of comments
* num_neg_words = the number of negative words found in the survey
* nw_to_c_ratio = the number of negative words divided by the number of comments

```{r Summary Table, echo=FALSE}
kable(survey_inf) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

Graphical representations of the summary statistics by Survey are shown below.

```{r Graphics, echo=FALSE, fig.width=10,fig.height=5}
#--------------------------------------------------------------------
#
# Build graphics from summary dataframe
#
#--------------------------------------------------------------------

# Number of coments and responses by survey
num_c_and_r <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=num_resps, color = "Responses"), group=1, size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=num_comments, color = "Comments"), group=1, size=2) +
  scale_colour_manual("", 
                      breaks = c("Responses", "Comments"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Count of Comments and Responses", subtitle = "Numbers of each by Survey") + ylab("Number")

# Ratio of comments to responses
ratio_c_to_r <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=c_to_r_ratio, color = "Ratios", group=1), size=2) +
  scale_colour_manual("", breaks = c("Ratios"), values = c("#000099")) +
  labs(title = "Ratio of Comments to Responses", subtitle = "Ratio By Survey") + ylab("Proportion of Comments")  

# Arrange the two plots for pasting into deck
grid.arrange(num_c_and_r, ratio_c_to_r, ncol = 2)

# Positive words vs. comments
pw_vs_c <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=num_pos_words, color = "Positive Words", group=1), size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=num_comments, color = "Comments", group=1), size=2) +
  scale_y_continuous(limits=c(10, 60)) +
  scale_colour_manual("", 
                      breaks = c("Positive Words", "Comments"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Positive Words Compared to Comments", subtitle = "Number of each by Survey") + ylab("Number of Each")

# Negative words vs. comments
nw_vs_c <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=num_neg_words, color = "Negative Words", group=1), size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=num_comments, color = "Comments", group=1), size=2) +
  scale_y_continuous(limits=c(10, 60)) +
  scale_colour_manual("", 
                      breaks = c("Negative Words", "Comments"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Negative Words Compared to Comments", subtitle = "Number of each by Survey") + ylab("Number of Each")

# Arrange the two plots for pasting into deck
grid.arrange(pw_vs_c, nw_vs_c, ncol = 2)

# Positive and negative words to comments ratios
p_vs_n <- ggplot() +
  geom_line(data=survey_inf, aes(x=Survey, y=pw_to_c_ratio, color = "Positive", group=1), size=2) +
  geom_line(data=survey_inf, aes(x=Survey, y=nw_to_c_ratio, color = "Negative", group=1), size=2) +
  scale_colour_manual("", 
                      breaks = c("Positive", "Negative"),
                      values = c("#0072B2", "#CC0000")) +
  labs(title = "Ratios of Positive & Negative Words to Comments", subtitle = "Ratio Comparisons by Survey") +
  ylab("# Words / # Comments")  

# Arrange the two plots for pasting into deck
grid.arrange(p_vs_n, ncol = 2)
```

`r pagebreak()`

### Appendix - Summary of Positive Vocabularly Words

**Positive Vocabulary word counts / occurrences**

```{r Display Positive Results, echo=FALSE}
kable(pos_df) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

`r pagebreak()`

### Appendix - Summary of Negative Vocabularly Words

**Negative Vocabulary word counts / occurrences**

```{r Display Negative Results, echo=FALSE}
kable(neg_df) %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

`r pagebreak()`

### Appendix - A Word Cloud Version of All Comments

This word cloud was created using one of the available tools on the internet (in this case, https://wordart.com) and then feeding the entire comments set into the application. Common words were automatically removed (in, the, a, at, etc.).

![Word Cloud of All Survey Comments](3-CustSatReport-Comments.png)

```{r echo=FALSE}
#--------------------------------------------------------------------
#
# End
#
#--------------------------------------------------------------------
```

